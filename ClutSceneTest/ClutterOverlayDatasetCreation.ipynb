{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clutter Overlay Dataset Creation\n",
    "Alex Denton, 25 Aug 2022, Thesis work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file overlays cropped SAR objects onto MSTAR clutter backgrounds using OpenCV and Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inputs:</b>\n",
    "1. SAR Image Directory\n",
    " - Chips and Clutter Scenes\n",
    " - grayscale, 8-bit\n",
    "\n",
    "<b>Outputs:</b><br>\n",
    "1. Clutter with overlays\n",
    " - same density of overlays\n",
    "\n",
    "<b>Notes:</b><br>\n",
    "1. The noise is recalculated at each resolution, not simply downsampled.\n",
    "2. The clutter patches need to be randomly sampled from the clutter dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from randowm import randint\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# Custom Functions\n",
    "from plotting import MultiPlots, OverContour, LayersPlot\n",
    "from SarClass import *\n",
    "from SupportFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "What specifics are will define this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjOfInterest = ['m35','2s1','m1']\n",
    "Resolution = 0.5  # m\n",
    "jit_step = 2  # step size for jitter\n",
    "jit_square = 3  # 3^2 images after jitter data augmentation\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Paths (relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chip_dir  = 'E:\\PycharmProjects/ChipOverlay/test_images/SAMPLE_OpenCV/images/bmp2'\n",
    "chip_dir = [fr\"/test_images/SAMPLE_OpenCV/images/{ooi}\" for ooi in ObjOfInterest]\n",
    "#chip_dir = [r'/test_images/SAMPLE_OpenCV/images/m35',\n",
    "#            r'/test_images/SAMPLE_OpenCV/images/2s1',\n",
    "#            r'/test_images/SAMPLE_OpenCV/images/m1']\n",
    "annot_dir = '/test_images/SAMPLE_OpenCV/annotations'\n",
    "coco_file = 'sample_synthetic_coco_format_sample1_converted.json'\n",
    "out_dir = r'/test_images/overlay_clutter'\n",
    "clutter_dir = r'/test_images/Clutter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Paths (relative)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#chip_dir = [r'/SAMPLE\\SAMPLE Public Master\\png_images\\decibel\\synth\\2s1',\n",
    "#            r'/SAMPLE\\SAMPLE Public Master\\png_images\\decibel\\synth\\m35',\n",
    "#            r'/SAMPLE\\SAMPLE Public Master\\png_images\\decibel\\synth\\m1']\n",
    "chip_dir = [fr'/SAMPLE/SAMPLE Public Master/png_images/decibel/synth/{ooi}'\" for ooi in ObjOfInterest]\n",
    "annot_dir = r'/SAMPLE'\n",
    "coco_file = 'sample_synthetic_coco_format_sample1_converted.json'\n",
    "out_dir = r'\\DATASET_Chip_Characterization\\Set1_M35_2s1_M1'\n",
    "clutter_dir = r'\\CLUTTER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure 'out_dir' exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{out_dir}/'):\n",
    "    os.mkdir(os.path.join(out_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chips\n",
    "Build list of all png file names in chip_dir, but drop the \".png\" b/c this will be the list of object names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in len(chip_dir)  # import multiple chip types for simultaneous integration\n",
    "    os.chdir(chip_dir[m])  # change to chip_dir\n",
    "    chips = [_chip.split('.')[0] for _chip in os.listdir() if _chip.endswith(\".png\") and not _chip.startswith('.')]  # 'chips' is list of str\n",
    "\n",
    "    # Create SarImage/SampleChip instances for each image\n",
    "    chips = [SampleChip(f'{chip_dir[m]}/{_chip}.png') for _chip in chips]  # 'chips' is list of objects\n",
    "    print(f'{len(chips)} chip objects created')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clutter\n",
    "Also load and treat clutter for the clutter background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(clutter_dir)  # change to clutter_dir\n",
    "clutters = [_clutter.split('.')[0] for _clutter in os.listdir() if _clutter.endswith(\".png\")]  # 'clutters' is list of str\n",
    "clutters = [MstarClutter(f'{clutter_dir}/{_clutter}.png') for _clutter in clutters]  # 'clutters' is list of objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Masks and Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### AFRL Given Masks #######\n",
    "# # Get mask info for each new chip and calculate histograms\n",
    "# for _chip in tqdm(chips, total=len(chips), desc=\"Importing Coco masks\"):\n",
    "#     os.chdir(annot_dir)  # change to annotation directory\n",
    "#     keep1 = _chip.mask_coco(coco_file, debug=debug)  # returns 'True' if needs to be deleted\n",
    "#     if keep1:\n",
    "#         keep2 = _chip.histComb()  # calculate object_mean, shadow_mean, and background_mean\n",
    "#         if not keep2:\n",
    "#             # print(f'Masks missing for {_chip.name}')\n",
    "#             pass\n",
    "#     else:\n",
    "#         # print(f'cannot find {_chip.name}\\nremoving from list...')\n",
    "#         pass\n",
    "#     if not keep1 or not keep2:  # if either is 'True' then delete\n",
    "#         chips.remove(_chip)  # remove from list\n",
    "#         del _chip  # delete object instance from memory\n",
    "# print(f'Masks uploaded / Histograms calculated for {len(chips)} chips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Masks - Chips\n",
    "Using <i>.mask_threshold()</i> because the AFRL mask dataset was incomplete.<br>\n",
    "<b>HistComb</b> assigns .shadow_mean and .background_mean to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _chip in chips:\n",
    "    # create masks based on thresholding\n",
    "    _chip.mask_threshold(bins=256, blur_kernel=[7,7], object_offset=1, shadow_offset=0.33, debug=False)\n",
    "    # assign .shadow_mean and .background_mean to each image in question\n",
    "    _chip.histComb(bins = 256, debug=False)\n",
    "print(f'Masks created / Histograms calculated for {len(chips)} chip images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [_chip.feather(shadow_dilation=3, debug=debug) for _chip in chips]  # generates chip.comb_alpha\n",
    "# [_chip.feather(kernel_sz=(3,3), shadow_dilation=3, debug=debug) for _chip in tqdm(chips, total=len(chips), desc='Feathering')]  # generates chip.comb_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feather</b> runs dilation and Gaussian blur routines to blend the overlay. Routine found in <i>SarClass.py</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _chip in tqdm(chips, total=len(chips), desc='Feathering'):\n",
    "    keep = _chip.feather(kernel_sz=(3,3), shadow_dilation=0, debug=debug)\n",
    "    if not keep:\n",
    "        # print(f'no shadow_mask for {_chip.name}\\nid number {_chip.image_id}')\n",
    "        chips.remove(_chip)\n",
    "        del _chip\n",
    "print(f'Feathering complete for {len(chips)} chips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Masks - Clutter\n",
    "The function <i><b>.MstarClutter()</b></i> aready ran <i>.mask_threshold()</i> because there are no provided mask for this set.<br>\n",
    "<b>HistComb</b> assigns .shadow_mean and .background_mean to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_clutter.histComb() for _clutter in tqdm(clutters, total=(len(clutters)), desc=\"Preparing Clutter\")]\n",
    "print(f'Masks created / Histograms calculated for {len(clutters)} background clutter images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "<b>Jitter</b> adds 9-point movement to provide variability to the dataset (data augmentation). <br>\n",
    "Note that <i>.jitter()</i> returns a list of objects. Each objects is a new instance of the original chip with only 'name', 'original', and 'comb_alpha' modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _jitter(sets,step=jit_step,square=jit_square):\n",
    "    set_jit = []\n",
    "    \n",
    "    for _set in tqdm(sets, total=len(set), desc=f'Jittering {sets}'):\n",
    "        keep = _set.jitter(step,square,debug=False)\n",
    "        if not keep:  # if returned False for error\n",
    "            print(f\"No comb_alpha for {_set.name}\\nid {_set.image_id}\")\n",
    "            chips.remove(_set)\n",
    "            del _set\n",
    "        set_jit += keep\n",
    "    \n",
    "    print(f'Jittering complete for {len(sets)} images')\n",
    "    return set_jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chips_jit = _jitter(chips)\n",
    "clutters_jit = _jitter(clutters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust resolution of chips_jit and clutters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = Resolution  # m\n",
    "\n",
    "chips = [_chip.iso_down_sample(old_res=(_chip.resCross,_chip.resRange), new_res=new_res) for _chip in tqdm(chips_jit, total=len(chips_jit), desc='Downsample chips_jit 0.5')]  # .comb_alpha is [grayscale, alpha_mask, max_dilation]\n",
    "clutters = [down_sample(_clutter, old_res=(_chip.resCross,_chip.resRange), new_res=new_res) for _clutter in tqdm(clutters_jit, total=len(clutters), desc='Downsample clutter 0.5')]  # .comb_alpha is [grayscale, alpha_mask, max_dilation]\n",
    "\n",
    "del chips_jit, clutters_jit  # we're done with these and will remove them from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "At this point we have two datasets - chips and clutter. Each is a list of objects with masks and labels. Each has been augmented by jittering and then downsampled to a lower resolution.<br><br>\n",
    "Next, we will being the overlay procedure...\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    This is as far as I have gone...\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Density and Distrobution of Chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(clutters)} clutter scenes after augmentation.\\n')\n",
    "print(f'There are:\\n')\n",
    "for n in len(ObjOfInterest):\n",
    "    print(f'\\t{len(chips.name(ObjOfInterest[n]))} chips of {ObjOfInterest[n]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chips_per_clutter = 3  # density of THIS CHIP ONLY (will run the whole routine again to add more chip classes\n",
    "[setattr(clutter, 'chip_count', 0) for clutter in clutters]  #\n",
    "# Total chips that will be overlaid (at each resolution\n",
    "total_overlays = len(clutters)*chips_per_clutter\n",
    "# What percent of chips will actually be used?\n",
    "chips_to_use = total_overlays/len(chips) # gives an int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay Chips on Clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since patch is different for each image, it must be generated on-the-fly. Additionally, each patch must be histogram balanced to the chip's object/shadow. See BRV.ipynb for details on this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set through each clutter scene\n",
    "for _clutter in tqdm(clutters, total= len(clutters), desc = 'Overlaying chips on clutter'):\n",
    "    while _clutter.chip_count < chips_per_clutter:\n",
    "\n",
    "        # Pick a cchip image at random\n",
    "        if len(chips) > 1:\n",
    "            rand_chip = chips[random.randint(0, len(chips))-1 ]\n",
    "        else:\n",
    "            rand_chip = chips  # the last one remaining\n",
    "\n",
    "        # Put the chip in a random place\n",
    "        _clutter.overlay_clutter(rand_chip, out_dir=out_dir, debug=True)\n",
    "\n",
    "        # Remove the used chip from the set\n",
    "\n",
    "        '''\n",
    "        # Cut a random patch and resize\n",
    "        w = _chip.width  # this value is the original (without downsampling)\n",
    "        h = _chip.height\n",
    "        x, y = _clutter.rand_patch(w, h)\n",
    "        patch = _clutter.cut_patch(x, y, w, h)\n",
    "        _patch = patch.copy()  # break the connection to the original clutter image to prevent corruption\n",
    "    \n",
    "        # Scale Chip Histogram to Match Patch (forward)\n",
    "        ps0 = ptSlope([_chip.shadow_mean, 0], [_clutter.shadow_mean, 1])\n",
    "        ps1 = ptSlope([_chip.background_mean, 0], [_clutter.background_mean, 1])\n",
    "    \n",
    "        _int = intPt(ps0, ps1)\n",
    "    \n",
    "        _chip = distort(_int, _chip)\n",
    "        _chip = _chip.astype(np.uint8)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
